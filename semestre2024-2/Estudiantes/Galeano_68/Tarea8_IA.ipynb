{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPfig3DZly2HhrH4ISimtok"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-FWN2UzmABgd","executionInfo":{"status":"ok","timestamp":1738002265760,"user_tz":300,"elapsed":50393,"user":{"displayName":"William Esneider Galeano Sierra","userId":"09337955867911371886"}},"outputId":"cb975d2e-bf4e-4709-b59f-e533d63ee607"},"outputs":[{"output_type":"stream","name":"stdout","text":["Primeras filas del conjunto de datos:\n","   sepal_length  sepal_width  petal_length  petal_width  Target\n","0           5.1          3.5           1.4          0.2       0\n","1           4.9          3.0           1.4          0.2       0\n","2           4.7          3.2           1.3          0.2       0\n","3           4.6          3.1           1.5          0.2       0\n","4           5.0          3.6           1.4          0.2       0\n","\n","Entrenando y evaluando el modelo: Logistic Regression\n","Matriz de confusión:\n","[[15  0  0]\n"," [ 0 14  1]\n"," [ 0  3 12]]\n","Reporte de clasificación:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        15\n","           1       0.82      0.93      0.88        15\n","           2       0.92      0.80      0.86        15\n","\n","    accuracy                           0.91        45\n","   macro avg       0.92      0.91      0.91        45\n","weighted avg       0.92      0.91      0.91        45\n","\n","\n","Entrenando y evaluando el modelo: Support Vector Machine\n","Matriz de confusión:\n","[[15  0  0]\n"," [ 0 14  1]\n"," [ 0  2 13]]\n","Reporte de clasificación:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        15\n","           1       0.88      0.93      0.90        15\n","           2       0.93      0.87      0.90        15\n","\n","    accuracy                           0.93        45\n","   macro avg       0.93      0.93      0.93        45\n","weighted avg       0.93      0.93      0.93        45\n","\n","\n","Entrenando y evaluando el modelo: Random Forest\n","Matriz de confusión:\n","[[15  0  0]\n"," [ 0 14  1]\n"," [ 0  4 11]]\n","Reporte de clasificación:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        15\n","           1       0.78      0.93      0.85        15\n","           2       0.92      0.73      0.81        15\n","\n","    accuracy                           0.89        45\n","   macro avg       0.90      0.89      0.89        45\n","weighted avg       0.90      0.89      0.89        45\n","\n","\n","Mejores hiperparámetros para Random Forest:\n","{'classifier__max_depth': None, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 50}\n","\n","Reporte de clasificación del modelo optimizado:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        15\n","           1       0.78      0.93      0.85        15\n","           2       0.92      0.73      0.81        15\n","\n","    accuracy                           0.89        45\n","   macro avg       0.90      0.89      0.89        45\n","weighted avg       0.90      0.89      0.89        45\n","\n"]}],"source":["# Importar librerías necesarias\n","import numpy as np\n","import pandas as pd\n","from sklearn import datasets\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import SVC\n","from sklearn.linear_model import LogisticRegression\n","\n","# 1. Cargar el conjunto de datos\n","# Usamos el conjunto de datos Iris como ejemplo\n","iris = datasets.load_iris()\n","X = iris.data  # Características\n","y = iris.target  # Etiquetas\n","\n","# Crear un DataFrame para mejor visualización\n","feature_names = [name.replace(\" (cm)\", \"\").replace(\" \", \"_\") for name in iris.feature_names]\n","df = pd.DataFrame(X, columns=feature_names)\n","df['Target'] = y\n","\n","# Mostrar las primeras filas del conjunto de datos\n","print(\"Primeras filas del conjunto de datos:\")\n","print(df.head())\n","\n","# 2. Dividir los datos en conjuntos de entrenamiento y prueba\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n","\n","# 3. Crear una función para probar diferentes modelos\n","def evaluate_models(models, X_train, X_test, y_train, y_test):\n","    \"\"\"\n","    Entrenar y evaluar diferentes modelos de clasificación.\n","\n","    Args:\n","        models (dict): Diccionario con los nombres y las instancias de los modelos.\n","        X_train, X_test, y_train, y_test: Conjuntos de datos de entrenamiento y prueba.\n","\n","    Returns:\n","        None. Imprime el rendimiento de cada modelo.\n","    \"\"\"\n","    for name, model in models.items():\n","        print(f\"\\nEntrenando y evaluando el modelo: {name}\")\n","        pipeline = Pipeline([\n","            ('scaler', StandardScaler()),  # Escalado de datos\n","            ('classifier', model)         # Modelo\n","        ])\n","\n","        # Entrenar el modelo\n","        pipeline.fit(X_train, y_train)\n","\n","        # Realizar predicciones\n","        y_pred = pipeline.predict(X_test)\n","\n","        # Evaluar el modelo\n","        print(\"Matriz de confusión:\")\n","        print(confusion_matrix(y_test, y_pred))\n","        print(\"Reporte de clasificación:\")\n","        print(classification_report(y_test, y_pred))\n","\n","# 4. Definir los modelos a probar\n","models = {\n","    'Logistic Regression': LogisticRegression(max_iter=200, random_state=42),\n","    'Support Vector Machine': SVC(kernel='rbf', probability=True, random_state=42),\n","    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n","}\n","\n","# 5. Evaluar los modelos\n","evaluate_models(models, X_train, X_test, y_train, y_test)\n","\n","# 6. Optimizar hiperparámetros de un modelo (ejemplo con Random Forest)\n","param_grid = {\n","    'classifier__n_estimators': [50, 100, 200],\n","    'classifier__max_depth': [None, 10, 20],\n","    'classifier__min_samples_split': [2, 5, 10]\n","}\n","\n","# Crear un pipeline con escalado y modelo\n","pipeline = Pipeline([\n","    ('scaler', StandardScaler()),\n","    ('classifier', RandomForestClassifier(random_state=42))\n","])\n","\n","# Usar GridSearchCV para buscar los mejores hiperparámetros\n","grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n","grid_search.fit(X_train, y_train)\n","\n","print(\"\\nMejores hiperparámetros para Random Forest:\")\n","print(grid_search.best_params_)\n","\n","# Evaluar el mejor modelo en el conjunto de prueba\n","y_pred_optimized = grid_search.best_estimator_.predict(X_test)\n","print(\"\\nReporte de clasificación del modelo optimizado:\")\n","print(classification_report(y_test, y_pred_optimized))\n"]},{"cell_type":"code","source":[],"metadata":{"id":"txN8CkJHALZA"},"execution_count":null,"outputs":[]}]}