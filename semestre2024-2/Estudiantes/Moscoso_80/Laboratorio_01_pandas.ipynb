{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nB0enqgBgefd"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/CienciaDatosUdea/002_EstudiantesAprendizajeEstadistico/blob/main/semestre2024-2/Laboratorios/Laboratorio_01_pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Laboratorio 1.0: \n",
    "\n",
    "## Series de tiempo\n",
    "\n",
    "El siguiente [dataset](https://raw.githubusercontent.com/hernansalinas/Curso_aprendizaje_estadistico/main/datasets/Pandas_data_historical_dataEURUSD.csv) contiene información del precio del eur/usd  desde el 05/07/2022/ hasta el 12/05/2023 con periodicidad de una hora. El data frame contiene el precio de apertura, cierrre, valor más bajo cotizado, valor más alto cotizado, volumen, spread etc. Para este dataset, realizar lo siguiente:\n",
    "\n",
    "\n",
    "1. Leer el dataset desde el github.\n",
    "2. Definir como indice la columna time.\n",
    "3. Obtenga información del data frame.\n",
    "\n",
    "4. Determine si hay null, nan en el data frame.\n",
    "\n",
    "5. Emplea la notacion Pascal Case y trabaja solo con la columa del precio de cierre del eur/usd.  \n",
    "\n",
    "6. Ahora vamos a determinar cual es la mejor distribución estadística que se ajusta a la diferencia del precio de cierre cada hora, para ello realizamos lo siguiente:\n",
    "- Determine la diferencia de precio entre horas, agregue una nueva columna llamada DiffPrice, en este punto tu dataframe debe tener solo dos columnas Close, DiffPrice y el indice debe ser el tiempo.\n",
    "- Para la nueva columna construya un histograma de los datos.\n",
    "- Determine la mejor distribucion estadística que se ajusta al histograma anterior, para ello puede emplear lo siguente:\n",
    "\n",
    "\n",
    "https://pypi.org/project/fitter/\n",
    "\n",
    "```python\n",
    "\n",
    "\n",
    "from fitter import Fitter, get_common_distributions, get_distributions\n",
    "\n",
    "f = Fitter(data,\n",
    "           distributions=['gamma',\n",
    "                          'lognorm',\n",
    "                          \"beta\",\n",
    "                          \"burr\",\n",
    "                          \"norm\"])\n",
    "f.fit()\n",
    "f.summary()\n",
    "#Indentificamos la mejor distribucion con el error cuadratico medio\n",
    "f.get_best(method = 'sumsquare_error')\n",
    "#Indentificamos parametros de la distrubicion beta\n",
    "f.fitted_param[\"beta\"]\n",
    "\n",
    "```\n",
    "\n",
    "Con el metodo get_distributions(), podemos ver todas las distribuciones estadisticas de la libreria. Ajusta a la mejor.  Puede consultar [esta](https://medium.com/the-researchers-guide/finding-the-best-distribution-that-fits-your-data-using-pythons-fitter-library-319a5a0972e9)  página si desea ver un ejemplo.\n",
    "\n",
    "\n",
    "7. Para el data frame, seleccionemos solo los datos del 2023.\n",
    "\n",
    "8. El comando groupby permite agrupar los datos con la periodicidad deseada: 1 dias, 2 dias, 1 mes etc. Determina el promedio con una periodicidad de 15 dias, con periodidicidad de 1 semana, y una periodicidad de 1 mes\n",
    "\n",
    "```python\n",
    "  df.groupby(pd.Grouper(key='time', freq='15D')).mean()\n",
    "```\n",
    "\n",
    "9. Para los datos asociados a los meses de 2023, construya un histograma para cada mes.  Para ello puedo emplear el metodo groupby. Notetese que si no  realiza una operación después de aplicar el metodo grouby, podrias iterar sobre dicho objeto, por ejemplo:\n",
    "\n",
    "```python\n",
    "q=df.groupby(pd.Grouper(key='time', freq='15D'))\n",
    "\n",
    "for name, group in q:\n",
    "  print(name, group)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzhBd58dWJXq"
   },
   "source": [
    "## Análisis de datos con pandas. \n",
    "\n",
    "Para el siguiente [dataset](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29) realizar lo siguiente:\n",
    "\n",
    "\n",
    "1. Leer los datos desde una página web.\n",
    "\n",
    "2. Renombrar las columnas en formato PascalCase.\n",
    "\n",
    "3. Utilizar los métodos `head()`, `tail()`, `describe()` e `info()` para obtener información sobre el `DataFrame`.\n",
    "\n",
    "4. Contabilizar la cantidad de valores nulos (`null` o `NaN`) en el `DataFrame`.\n",
    "   Si se encuentran valores nulos, ¿qué estrategia propondrías para reemplazarlos?\n",
    "\n",
    "5. Identificar los valores únicos en la columna `target` que representan las etiquetas B y M (Benigno y Maligno, respectivamente).\n",
    "   Utiliza el método `unique()` para mostrar estos valores.\n",
    "\n",
    "6. Realizar un conteo de los casos etiquetados como B y M utilizando la librería `seaborn` y el método `countplot()`:\n",
    "\n",
    "```python\n",
    "import seaborn as sns\n",
    "sns.countplot?\n",
    "```\n",
    "\n",
    "7. Agregar una nueva columna llamada `DiagnosisNumeric` donde se asigna el valor 0 a la etiqueta B (Benigno) y el valor 1 a la etiqueta M (Maligno).\n",
    "\n",
    "\n",
    "8. Normalizar cada columna respecto a su media y desviación estándar utilizando la fórmula:  \n",
    "   `(x - mean(x)) / std(x)`\n",
    "\n",
    "9. Agrupar características similares y calcular su promedio.\n",
    "   Para las siguientes características:\n",
    "\n",
    "```python\n",
    "['RadiusMean', 'TextureMean', 'PerimeterMean', 'AreaMean', 'SmoothnessMean', 'CompactnessMean', 'ConcavityMean', 'ConcavePointsMean', \"SymmetryMean\", \"FractalDimensionMean\"]\n",
    "```\n",
    "\n",
    "Usa expresiones regulares para identificar patrones comunes, como `radius1`, `radius2`,`radius3`, etc., y calcular los promedios. Por ejemplo:\n",
    "\n",
    "```python\n",
    "re.match(r'^[a-zA-Z_]+', \"holamundo12341\").group(0)\n",
    "```\n",
    "\n",
    "También puedes utilizar el método `startswith()` para buscar estos patrones en los nombres de las columnas.\n",
    "\n",
    "\n",
    "10. Crear un gráfico donde se muestre el histograma de la columna `RadiusMean` separado por las etiquetas B y M, utilizando colores diferentes (naranja y azul, respectivamente) para cada diagnóstico.\n",
    "\n",
    "11. Generar gráficos de violín para múltiples características.\n",
    "   Para las columnas:\n",
    "\n",
    "   - `RadiusMean`\n",
    "   - `TextureMean`\n",
    "   - `PerimeterMean`\n",
    "   - `AreaMean`\n",
    "   - `SmoothnessMean`\n",
    "   - `CompactnessMean`\n",
    "   - `ConcavityMean`\n",
    "   - `ConcavePointsMean`\n",
    "   - `Symmetry3`\n",
    "   - `FractalDimension3`\n",
    "\n",
    "   Realiza un gráfico múltiple tipo violín, como en el siguiente ejemplo:\n",
    "\n",
    "```python\n",
    "data = pd.melt(df.iloc[:, 0:10], id_vars=\"Diagnosis\", var_name=\"features\", value_name=\"value\")\n",
    "sns.violinplot(x=\"features\", y=\"value\", hue=\"Diagnosis\", data=data, split=True, inner=\"quart\")\n",
    "plt.xticks(rotation=45)\n",
    "```\n",
    "\n",
    "\n",
    "12.  Determinar y eliminar los valores atípicos (`outliers`) en la columna `RadiusMean`.\n",
    "\n",
    "Para identificarlos, construye un gráfico tipo `boxplot`:\n",
    "\n",
    "```python\n",
    "df.boxplot(column=\"RadiusMean\", by='Diagnosis', sym='k.', figsize=(18,6))\n",
    "```\n",
    "\n",
    "Usa el rango intercuartílico (IQR) para definir los outliers. Los valores fuera del rango [Q1 - 1.5 * IQR, Q3 + 1.5 * IQR] se consideran outliers. Ejemplo de cómo eliminar estos valores:\n",
    "\n",
    "```python\n",
    "Q1 = df['edad'].quantile(0.25)\n",
    "Q3 = df['edad'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "df = df[~((df['edad'] < (Q1 - 1.5 * IQR)) | (df['edad'] > (Q3 + 1.5 * IQR)))]\n",
    "```\n",
    "\n",
    "Otra alternativa es utilizar el puntaje Z para detectar `outliers`:\n",
    "\n",
    "```python \n",
    "df = df[(np.abs(stats.zscore(df['edad'])) < 3)]\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "13. Encontrar la matrix de correlación, emplear el metodo corr(), dentro de seaborn buscar el metodo heatmap() para realizar un grafico de la matrix de correlación.\n",
    "\n",
    "14. ¿Que otro tipo de gráficos pueden ser realizados para entender mejor los datos?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dg5T-MejYZf-"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nyhIUpJmfXQr"
   },
   "source": [
    "Hint:\n",
    "\n",
    "\n",
    "```python \n",
    "df['time'] =  pd.to_datetime(df.time)\n",
    "df.set_index(\"time\", inplace=True)\n",
    "df = df.drop(columns = [\"Unnamed: 0\"])\n",
    "df[\"DiffClose\"] = df.close.diff()\n",
    "df2 = df[[\"DiffClose\", \"close\"]][1:]\n",
    "df2.DiffClose.hist(bins=1000)\n",
    "\n",
    "\n",
    "!pip install fitter\n",
    "\n",
    "\n",
    "from fitter import Fitter, get_common_distributions, get_distributions\n",
    "\n",
    "f = Fitter(df2.DiffClose,\n",
    "           distributions=['gamma',\n",
    "                          'lognorm',\n",
    "                          \"beta\",\n",
    "                          \"burr\",\n",
    "                          \"norm\"])\n",
    "f.fit()a\n",
    "f.summary()\n",
    "#Indentificamos la mejor distribucion con el error cuadratico medio\n",
    "f.get_best(method = 'sumsquare_error')\n",
    "#Indentificamos parametros de la distrubicion beta\n",
    "f.fitted_param[\"beta\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f = Fitter(df2.DiffClose,\n",
    "           distributions=['gamma',\n",
    "                          'genhyperbolic',\n",
    "                          \"beta\",\n",
    "                          \"burr\",\n",
    "                          \"norm\"])\n",
    "f.fit()\n",
    "f.summary()\n",
    "#Indentificamos la mejor distribucion con el error cuadratico medio\n",
    "f.get_best(method = 'sumsquare_error')\n",
    "#Indentificamos parametros de la distrubicion beta\n",
    "f.fitted_param[\"beta\"]\n",
    "\n",
    "\n",
    "\n",
    "df2.groupby(pd.Grouper(freq='15D')).mean()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
