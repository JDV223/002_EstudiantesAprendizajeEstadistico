{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUQ8Ccq2wiQe"
      },
      "source": [
        "# Juan Pablo Montenegro Erazo - CC1007778301\n",
        "\n",
        "1. Construir un clase  que permita definir una red neuronal con la topología\n",
        "deseada y la función de activación para cada capa, para ello deberá construir una funcion Topology con el número de capas de la red neuronal :\n",
        "\n",
        "Topology = [n_x, n_h1, n_h2, n_h3, ...,n_y]\n",
        "\n",
        "En este caso:\n",
        "- $n^{[0]}=n_x$ seran los valores de entradas de la capa de entrada\n",
        "- $n^{[1]}=n_{h1}$ Primera capa oculta de la red neuronal\n",
        "- $n^{[2]}=n_{h2}$ Segunda capa oculta de la red neuronal\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        "\n",
        "- $n^{[l]}=n_{hl}$ Segunda capa oculta de la red neuronal\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        ".\n",
        "\n",
        "- $n^{[L]}=n_{y}$ Segunda capa oculta de la red neuronal\n",
        "\n",
        "donde\n",
        "\n",
        "- $\\mathrm{n_x}$: valores de entrada\n",
        "- $\\mathrm{n_{h1}}$: hidden layer 1\n",
        "- $\\mathrm{n_{h2}}$: hidden layer 2\n",
        "- $\\mathrm{n_y}$: last layer\n",
        "\n",
        "- $n^{[L]}=n_{y}$ Segunda capa oculta de la red neuronal\n",
        "\n",
        "\n",
        "También definir una lista con las funciones de activaciones para cada capa.\n",
        "\n",
        "\n",
        "activation=[None, relu, relu, relu, ...,sigmoid]\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "a. Cada unas de las capas deberá tener los parámetros de inicialización de manera aleatoria:\n",
        "\n",
        "\n",
        "La matriz de parametros para cada capa debera tener:\n",
        "\n",
        "\n",
        "$\\mathrm{dim(\\vec{b}^{[l]})}=n^{[l]}$\n",
        "\n",
        "$\\mathrm{dim(\\vec{\\Theta}^{[l]})}=n^{[l]}\\times n^{[l-1]}$\n",
        "\n",
        "Lo anteriores parametros deberán estar en el constructor de la clase.\n",
        "\n",
        "\n",
        "b. Construya un metodo llamado output cuya salida serán los valores de Z y A\n",
        "\n",
        "\n",
        "$\\mathrm{dim(\\vec{\\cal{A}}^{[l]})}=n^{[l-1]}\\times m $\n",
        "\n",
        "$\\mathrm{dim(\\vec{\\cal{Z}}^{[l]})}=n^{[l]}\\times m $."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4E-JbmM9YmU2"
      },
      "source": [
        "2. Construir un generalizacion de la red, en el que entrada el valor inicial\n",
        "y la red neuronal completa arroje la salida y la actualizacion de la red con los parametros deseados:\n",
        "\n",
        "  ```\n",
        "  A, nn = forward_pass(A0, nn_red)\n",
        "\n",
        " ```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Encontrar la funcion de coste.\n",
        "\n",
        "\n",
        "$$-\\frac{1}{m} \\sum\\limits_{i = 1}^{m} (y^{(i)}\\log\\left(a^{[L] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[L](i)}\\right)) \\tag{7}$$"
      ],
      "metadata": {
        "id": "uY4s_Ht-HTEn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q192DHiWlTws"
      },
      "source": [
        "4. Construir un codigo que permita realizar el BackwardPropagation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrndWsfgYy-a"
      },
      "source": [
        "# Solución\n",
        "\n",
        "Implementaremos los incisos 1, 2 y 4 en la siguiente celda de codigo; y el inciso 3 en la ultima celda de texto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unmcT2uXscVy"
      },
      "source": [
        "# Convenciones del codigo\n",
        "\n",
        "A continuación describiré las definiciones y convenciones que usé para construir el codigo\n",
        "\n",
        "## Matriz de pesos de la capa $l$\n",
        "\n",
        "Es la matriz que tiene como entradas todos los pesos de la capa $l$. Cada fila tiene los pesos que \"van\" hacia una neurona de esta capa, mientras que cada columna tiene los pesos que \"salen\" de una neurona de la capa $l-1$. Para ser más especificos llamemos $w^{[l]}_{ji}$ al peso de la $j$-esima neurona de la capa $l$ que está conectada a la $i$-esima neurona de la capa $l-1$. Si hay $r$ neuronas en la capa $l$, y la capa $l-1$ tiene $s$ neuronas, entonces la matriz de pesos de la capa $l$ es:\n",
        "\n",
        "\n",
        "$$W^{[l]} =\n",
        "\\begin{bmatrix}\n",
        "w^{[l]}_{11} & w^{[l]}_{12} & \\cdots & w^{[l]}_{1s} \\\\\n",
        "w^{[l]}_{21} & w^{[l]}_{22} & \\cdots & w^{[l]}_{2s} \\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "w^{[l]}_{r1} & w^{[l]}_{r2} & \\cdots & w^{[l]}_{rs}\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "$ $\n",
        "\n",
        "## Matriz bias de la capa $l$\n",
        "\n",
        "Es la matriz columna que tiene los bias de la capa $l$. Llamemos $b^{[l]}_{j}$ al bias de la $j$-esima neurona de esta capa, entonces si la capa $l$ tiene r neuronas, la matriz bias es:\n",
        "\n",
        "$$B^{[l]} =\n",
        "\\begin{bmatrix}\n",
        "b^{[l]}_{1} \\\\\n",
        "b^{[l]}_{2} \\\\\n",
        "\\vdots \\\\\n",
        "b^{[l]}_{r}\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "$ $\n",
        "\n",
        "## Matriz activación de la capa $l$\n",
        "\n",
        "Es la matriz que tiene como entradas todas las activaciones de la capa $l$ de todos los inputs que se le pasen a la red neuronal (Por ejemplo si mi red neuronal predice si en una imagen aparece un perro o un gato, cada imagen es un input). Cada fila tiene las activaciones de una misma neurona para los diferentes inputs, y cada columna tiene las activaciones de la capa para un mismo input. Para ser más especificos, llamemos $a^{[l](k)}_{j}$ a la activación de la $j$-esima neurona de la capa $l$, cuando se le ha pasado a la red neuronal el $k$-esimo input. Si se le pasan $m$ inputs, y la capa tiene $r$ neuronas, entonces la matriz de activación de la capa $l$ es:\n",
        "\n",
        "$$A^{[l]} =\n",
        "\\begin{bmatrix}\n",
        "a^{[l](1)}_{1} & a^{[l](2)}_{1} & \\cdots & a^{[l](m)}_{1} \\\\\n",
        "a^{[l](1)}_{2} & a^{[l](2)}_{2} & \\cdots & a^{[l](m)}_{2} \\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "a^{[l](1)}_{r} & a^{[l](2)}_{r} & \\cdots & a^{[l](m)}_{r}\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "$ $\n",
        "\n",
        "## Matriz Z de la capa $l$\n",
        "\n",
        "Es la matriz que tiene como entradas los argumentos de la función de activación de esta capa para todos los inputs que se le pasen a la red. Le he puesto este nombre porque al argumento de una función de activación lo llamamos $z$ en clase. Cada fila de la matriz tiene los z de una misma neurona para diferentes inputs, y cada columna tiene los z de la capa para un mismo input. Así pues la matriz Z de la capa $l$ es:\n",
        "\n",
        "$$Z = W^{[l]} A^{[l-1]} + B^{[l]}$$\n",
        "\n",
        "$ $\n",
        "\n",
        "Si hay $m$ inputs, $r$ neuronas en la capa $l$, y $s$ en la capa $l-1$, entonces $Z$ también se puede escribir como\n",
        "\n",
        "$ $\n",
        "\n",
        "$$Z^{[l]} =\n",
        "\\begin{bmatrix}\n",
        "w^{[l]}_{11} & w^{[l]}_{12} & \\cdots & w^{[l]}_{1s} \\\\\n",
        "w^{[l]}_{21} & w^{[l]}_{22} & \\cdots & w^{[l]}_{2s} \\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "w^{[l]}_{r1} & w^{[l]}_{r2} & \\cdots & w^{[l]}_{rs}\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "a^{[l-1](1)}_{1} & a^{[l-1](2)}_{1} & \\cdots & a^{[l-1](m)}_{1} \\\\\n",
        "a^{[l-1](1)}_{2} & a^{[l-1](2)}_{2} & \\cdots & a^{[l-1](m)}_{2} \\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "a^{[l-1](1)}_{r} & a^{[l-1](2)}_{r} & \\cdots & a^{[l-1](m)}_{r}\n",
        "\\end{bmatrix} +\n",
        "\\begin{bmatrix}\n",
        "b^{[l]}_{1} \\\\\n",
        "b^{[l]}_{2} \\\\\n",
        "\\vdots \\\\\n",
        "b^{[l]}_{r}\n",
        "\\end{bmatrix}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57-vdD3RDvBJ"
      },
      "source": [
        "## Tensores en Back Propagation\n",
        "\n",
        "En el metodo `back_propagation` de la clase `Red_Neuronal` definimos tensores de rango 3 que contienen la información necesaria para calcular el gradiente de la función de costo. Cada tensor tiene información de una capa especifica $l$, de la capa anterior, y de los datos de entrenamiento (o inputs).\n",
        "\n",
        "Para facilitar la lectura del código usé la siguiente convención en los ejes de los tensores:\n",
        "\n",
        "*   Eje 0: Recorre los datos de entrenamiento (o inputs) que se le pasan a la red\n",
        "*   Eje 1: Recorre las neuronas de la capa actual\n",
        "*   Eje 2: Recorre las neuronas de la anterior capa\n",
        "\n",
        "Si uno de los ejes del tensor es siempre 1, significa que no recorre los elementos de ese eje. Por ejemplo, los bias no se asocian a las neuronas de la anterior capa, entonces, un tensor de bias debería tener siempre dimension 1 en su segundo eje.\n",
        "\n",
        "$ $\n",
        "\n",
        "**Ejemplo de la convención:** la entrada `tensor_gradiente_pesos_actual[0][1][2]` es la componente del gradiente correspondiente al **primer dato de entrenamiento** del peso que conecta la **segunda neurona de la capa actual** del algoritmo, con la **tercer neurona de la capa anterior**. Osea es:\n",
        "\n",
        "$$\\frac{\\partial J^{[0]}}{\\partial w_{12}}$$\n",
        "\n",
        "$ $\n",
        "\n",
        "El método `back_propagation` crea 2 listas de matrices con las componentes del gradiente descendente. `self.lista_matrices_gradiente_pesos` es la lista respecto a los pesos y `self.lista_matrices_gradiente_bias` es respecto a los bias, así pues estas listas son solo otra forma de escribir el gradiente descendente de la red neuronal. Cada matriz de la lista le corresponde a una capa, comenzando con la capa 1 (la segunda capa). Cada matriz sigue la convención anterior, pues es el promedio sobre el eje 0 de su respectivo tensor:\n",
        "\n",
        "$$\\frac{\\partial J}{\\partial w_{ji}} = \\frac{1}{m} \\sum_{k = 0}^{m} \\frac{\\partial J^{[k]}}{\\partial w_{ji}}$$\n",
        "\n",
        "$$\\frac{\\partial J}{\\partial b_{j}} = \\frac{1}{m} \\sum_{k = 0}^{m} \\frac{\\partial J^{[k]}}{\\partial b_{j}}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Caulculos para realizar Back Propagation\n",
        "\n",
        "Para un mejor entendimiento del codigo mostrare a continuación las ecuaciones que usan en el metodo `back_propagation` en cada una de las entradas de los tensores definidos previamente.\n",
        "\n",
        "Para la neurona $j$ de la capa $l$, con el dato de entrenamiento $k$\n",
        "\n",
        "$$\\frac{\\partial J^{(k)}}{\\partial b_{j}^{[l]}} = \\frac{\\partial z_j^{[l](k)}}{\\partial b_{j}^{[l]}} \\frac{\\partial a_j^{[l](k)}}{\\partial z_{j}^{[l](k)}} \\frac{\\partial J^{(k)}}{\\partial a_{j}^{[l](k)}} = \\frac{\\partial a_j^{[l](k)}}{\\partial z_{j}^{[l](k)}} \\frac{\\partial J^{(k)}}{\\partial a_{j}^{[l](k)}}$$\n",
        "\n",
        "$ $\n",
        "\n",
        "$$\\frac{\\partial J^{(k)}}{\\partial w_{ji}^{[l]}} = \\frac{\\partial z_j^{[l](k)}}{\\partial w_{ji}^{[l]}} \\frac{\\partial a_j^{[l](k)}}{\\partial z_{j}^{[l](k)}} \\frac{\\partial J^{(k)}}{\\partial a_{j}^{[l](k)}} = a_i^{[l-1](k)} \\frac{\\partial J^{(k)}}{\\partial b_{j}^{[l]}}$$\n",
        "\n",
        "$ $\n",
        "\n",
        "$$\\frac{\\partial J^{(k)}}{\\partial a_i^{[l-1](k)}} = \\sum_{j=1}^{r} \\frac{\\partial z_j^{[l](k)}}{\\partial a_{i}^{[l-1](k)}} \\frac{\\partial a_j^{[l](k)}}{\\partial z_{j}^{[l](k)}} \\frac{\\partial J^{(k)}}{\\partial a_{j}^{[l](k)}} = \\sum_{j=1}^{r} w_{ji}^{[l]} \\frac{\\partial J^{(k)}}{\\partial b_{j}^{[l]}}$$\n",
        "\n",
        "$ $\n",
        "----------------------------\n",
        "\n",
        "Si tenemos $m$ datos de entrenamiento y $r$ neuronas en la capa $l$, entonces:\n",
        "\n",
        "$$\\frac{\\partial J}{\\partial b_{j}^{[l]}} = \\frac{1}{m} \\sum_{k=1}^{m} \\frac{\\partial J^{(k)}}{\\partial b_{j}^{[l]}}$$\n",
        "\n",
        "$$\\frac{\\partial J}{\\partial w_{ji}^{[l]}} = \\frac{1}{m} \\sum_{k=1}^{m} \\frac{\\partial J^{(k)}}{\\partial w_{ji}^{[l]}}$$\n",
        "\n",
        "$ $\n",
        "\n",
        "$\\frac{\\partial J}{\\partial b_{j}^{[l]}}$ y $\\frac{\\partial J}{\\partial w_{ji}^{[l]}}$ son las entradas de lo que llamo \"matriz_gradiente_bias\" y \"matriz_gradiente_pesos\" respectivamente. Cada capa de la red tiene estas 2 matrices, y todas las matrices_gradiente_bias y matrices_gradiente_pesos se guardan como atributos de la clase `Red_Neuronal` en las listas: `self.lista_matrices gradiente_bias` y `self.lista_matrices gradiente_pesos`. Estas listas se crean y se actualizan luego de ejecutar el metodo `back_propagation`, cuya unica función es hacer esto."
      ],
      "metadata": {
        "id": "k7ozPDlkrU7D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descenso del gradiente\n",
        "\n",
        "El metodo `actualizar_parametros` de la clase `Red_Neuronal`, realiza un paso $p$ del gradiente descendente, haciendo que cada \"matriz_gradiente\" actualice sus entradas de la siguiente manera:\n",
        "\n",
        "$$(b_{j}^{[l]})_{p+1} = (b_{j}^{[l]})_{p} - \\alpha \\frac{\\partial J}{\\partial b_j^{[l]}}$$\n",
        "\n",
        "$$(w_{ji}^{[l]})_{p+1} = (w_{ji}^{[l]})_{p} - \\alpha \\frac{\\partial J}{\\partial w_{ji}^{[l]}}$$\n",
        "\n",
        "Donde $\\alpha$ es el learning rate.\n",
        "\n",
        "Los parametros actualizados de la red se guardan como atributos de cada capa en `self.matriz_pesos` y `self.matriz_bias`\n",
        "\n",
        "$ $\n",
        "\n",
        "## Metodo entrenar\n",
        "\n",
        "El metodo `entrenar` de la clase `Red_Neuronal` recibe las entradas de la red del proceso de entrenamiento en una matriz llamada `matriz_entrenamiento`, donde cada columna representa un dato de entrenamiento. Recibe tambien las etiquetas a estas entradas en la matriz `matriz_labels`, donde cada columna es la etiqueta de un dato de entrenamiento. Por ultimo recibe el learning rate inicial y el número de pasos del gradiente descendente que se desee realizar en los parametros `alpha_inicial` y `numero_pasos`. Este metodo realiza todo el proceso del gradiente descendente con un learning rate variable.\n",
        "\n",
        "El learning rate se dobla cuando el algoritmo detecta que no ha habido un cambio de dirección del gradiente descendente en ningún momento, y además ya se han realizado 100 pasos del gradiente descendente. Esto sirve para hacerlerar el proceso cuando $\\alpha$ se elige demasiado pequeño.\n",
        "\n",
        "El learning rate se reduce a la mitad cuando el algoritmo detecta que ha habido un cambio de dirección en el gradiente descendente. Esto ocurre cuando el paso del descenso del gradiente \"se pasa\" del minimo, y ayuda a la convergencia del algoritmo a un minimo cercano.\n",
        "\n",
        "$ $\n",
        "\n",
        "## Metodo entrenar_por_lotes\n",
        "\n",
        "Por ultimo, el metodo de la clase `Red_Neuronal` llamado `entrenar_por_lotes` parte la `matriz_entrenamiento` en distintos lotes (batches), y entrena secuencialmente a la red recorriendo uno por uno estos lotes. Esto reduce el uso de la RAM que se necesita para entrenar al modelo.\n",
        "\n",
        "$ $\n",
        "\n",
        "Los demás detalles del código están explicados en los comentarios del mismo. Esto con la intención de que este texto explicativo no sea demasiado extenso."
      ],
      "metadata": {
        "id": "KVf0_TCLv7-X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "guI16oMck6xX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class Capa():\n",
        "\n",
        "    diccionario_funciones_activacion = {\"sigmoide\" : lambda Z : 1 / (1 + np.exp(-Z)),\n",
        "                                        \"identidad\" : lambda Z : Z}\n",
        "\n",
        "    def __init__(self, numero_entradas, numero_neuronas, string_funcion_activacion):\n",
        "        self.numero_entradas = numero_entradas\n",
        "        self.numero_neuronas = numero_neuronas\n",
        "        self.string_funcion_activacion = string_funcion_activacion\n",
        "        self.funcion_activacion = Capa.diccionario_funciones_activacion[string_funcion_activacion]\n",
        "\n",
        "        if string_funcion_activacion != \"identidad\" or numero_entradas != numero_neuronas: # Cuando no sea la capa de entrada\n",
        "            self.matriz_pesos = np.random.uniform(low=-1, high=1, size = (numero_neuronas, numero_entradas) ) # Las filas son los pesos que van hacia una neurona de la capa actual, mientras que las columnas son los pesos que salen de una neurona de la anterior capa\n",
        "            self.matriz_bias = np.random.uniform(low=-1, high=1, size = (numero_neuronas, 1) )\n",
        "\n",
        "\n",
        "    def actualizar_activaciones(self, matriz_activacion_anterior): # Cambia la matriz de activación de la capa, o la crea si no existe\n",
        "\n",
        "        self.matriz_Z = self.matriz_pesos @ matriz_activacion_anterior + self.matriz_bias\n",
        "        self.matriz_activacion = self.funcion_activacion(self.matriz_Z)\n",
        "\n",
        "\n",
        "    def output(self): # Metodo para cumplir con el inciso 1. b)\n",
        "        return (self.matriz_Z, self.matriz_activacion)\n",
        "\n",
        "\n",
        "\n",
        "class Red_Neuronal():\n",
        "\n",
        "    diccionario_derivadas = {\"sigmoide\" : lambda Z : np.exp(-Z)/((1 + np.exp(-Z))**2)} # Diccionario de derivadas. El valor es la derivada de la función que tiene el nombre de la clave\n",
        "\n",
        "    diccionario_costo = {\"mse\" : lambda A, Y : np.mean( np.sum( (A-Y)**2, axis=0)),\n",
        "                         \"logistic\" : lambda A, Y : -np.mean(Y*np.log(A) + (np.ones(Y.shape) - Y)*np.log(1 - A))} # Diccionario de funciones de costo. A es la matriz de la ultima activación, y Y es la matriz de labels\n",
        "\n",
        "    diccionario_delJ_dela = {\"mse\" : lambda a_j, y_j : 2*(a_j - y_j),\n",
        "                             \"logistic\": lambda a, y : (a - y)/(a*(1 - a))} # Diccionario que contiene la derivada parcial de J^(k) respecto a la activación de la ultima capa, de la neurona j-esima. Las llaves del diccionario representan la elección de J\n",
        "\n",
        "    def __init__(self, string_funcion_costo):\n",
        "\n",
        "        self.string_funcion_costo = string_funcion_costo\n",
        "        self.lista_capas = []\n",
        "\n",
        "\n",
        "    def agregar_capa(self, capa):\n",
        "        self.lista_capas.append(capa)\n",
        "\n",
        "\n",
        "    def ultima_capa(self):\n",
        "        return self.lista_capas[-1]\n",
        "\n",
        "    def topology(self, lista_topologia, lista_strings_funciones_a): # La lista_topologia tiene el numero de neuronas en cada capa, y lista_strings_funciones_a tiene las funciones de activación correspondientes a cada una de las capas\n",
        "\n",
        "        numero_entradas = lista_topologia[0]\n",
        "        indice_capa = 0\n",
        "\n",
        "        for numero_neuronas, string_funcion_a in zip(lista_topologia, lista_strings_funciones_a):\n",
        "\n",
        "            capa = Capa(numero_entradas, numero_neuronas, string_funcion_a)\n",
        "            self.agregar_capa(capa)\n",
        "            numero_entradas = lista_topologia[indice_capa]\n",
        "            indice_capa = indice_capa + 1\n",
        "\n",
        "\n",
        "    def actualizar_activaciones(self, matriz_entrada): # Cambia las matrices de activación de las capas, o las crea si no existen\n",
        "\n",
        "        self.lista_capas[0].matriz_activacion = matriz_entrada # CREACIÓN/ACTUALIZACIÓN DE LA MATRIZ DE ACTIVACIÓN EN LA CAPA DE ENTRADA\n",
        "        indice_capa_anterior = 0\n",
        "\n",
        "        for capa in self.lista_capas[1:]:\n",
        "            matriz_activacion_anterior = self.lista_capas[indice_capa_anterior].matriz_activacion\n",
        "            capa.actualizar_activaciones(matriz_activacion_anterior)\n",
        "            indice_capa_anterior = indice_capa_anterior + 1\n",
        "\n",
        "\n",
        "    def salida(self):\n",
        "        return self.ultima_capa().matriz_activacion\n",
        "\n",
        "\n",
        "    def evaluar_MNIST(self, matriz_test, matriz_labels): # Metodo para evaluar el desempeño en el dataset MNIST\n",
        "\n",
        "        self.actualizar_activaciones(matriz_test)\n",
        "        matriz_salida = self.salida()\n",
        "        array_salida = matriz_salida.T\n",
        "\n",
        "        aciertos = 0\n",
        "        total_datos = matriz_test.shape[1]\n",
        "\n",
        "        for salida, label in zip(array_salida, matriz_labels.T):\n",
        "            salida_real = np.argmax(salida)\n",
        "            label_real = np.argmax(label)\n",
        "\n",
        "            if salida_real == label_real:\n",
        "                aciertos = aciertos + 1\n",
        "\n",
        "        return aciertos/total_datos\n",
        "\n",
        "\n",
        "    def back_propagation(self, matriz_labels): # Devuelve las componentes del gradiente en 2 listas de matrices (lista_matrices_gradiente_pesos, lista_matrices_gradiente_bias). Cada matriz tiene las componentes del gradiente de una capa\n",
        "\n",
        "        L = len(self.lista_capas) - 1 # La capa 0 es la capa de entrada\n",
        "        delJ_dela = Red_Neuronal.diccionario_delJ_dela[self.string_funcion_costo] # derivada parcial de J respecto a la activacion de la ultima capa\n",
        "\n",
        "        self.lista_matrices_gradiente_bias = [] # Aquí estarán las matrices que contienen las derivadas parciales de J respecto a los bias\n",
        "        self.lista_matrices_gradiente_pesos = [] # Aquí estarán las matrices que contienen las derivadas parciales de J respecto a los pesos\n",
        "\n",
        "        for d in range(L): # Back propagation\n",
        "\n",
        "            capa_actual = self.lista_capas[L - d]\n",
        "            capa_anterior = self.lista_capas[L - d - 1]\n",
        "            string_funcion_activacion = capa_actual.string_funcion_activacion\n",
        "            derivada_funcion_activacion = Red_Neuronal.diccionario_derivadas[string_funcion_activacion]\n",
        "\n",
        "            matriz_activacion = capa_actual.matriz_activacion # Cada columna es un dato de entrenamiento, y cada fila es una neurona\n",
        "            matriz_activacion_anterior = capa_anterior.matriz_activacion # Cada columna es un dato de entrenamiento, y cada fila es una neurona\n",
        "            matriz_Z = capa_actual.matriz_Z\n",
        "\n",
        "            tensor_activacion = np.expand_dims(matriz_activacion.T, axis=2) # El eje 0 son los datos de entrenamiento, el eje 1 la capa actual, y el eje 2 solo tiene dimension 1\n",
        "            tensor_activacion_anterior = np.expand_dims(matriz_activacion_anterior.T, axis=1) # El eje 0 son los datos de entrenamiento, el eje 1 solo tiene una dimension, y el eje 2 es la capa anterior\n",
        "            tensor_Z = np.expand_dims(matriz_Z.T, axis=2) # El eje 0 son los datos de entrenamiento, el eje 1 la capa actual, y el eje 2 solo tiene dimension 1\n",
        "\n",
        "            tensor_labels = np.expand_dims(matriz_labels.T, axis=2) # El eje 0 son los datos de entrenamiento, el eje 1 son los labels, y el eje 2 solo tiene dimension 1\n",
        "\n",
        "            if d == 0:\n",
        "                tensor_puente = delJ_dela(tensor_activacion, tensor_labels)\n",
        "\n",
        "            tensor_gradiente_bias_actual = derivada_funcion_activacion(tensor_Z) * tensor_puente # Tensor con la información para calcular las derivadas parciales de los bias de la capa actual. El eje 0 es el dato de entrenamiento, el eje 1 la capa actual, y el eje 2 la capa anterior\n",
        "            tensor_gradiente_pesos_actual = tensor_activacion_anterior * tensor_gradiente_bias_actual # Tensor con la información para calcular las derivadas de los pesos de la capa actual. El eje 0 es el dato de entrenamiento, el eje 1 la capa actual, y el eje 2 la capa anterior\n",
        "\n",
        "            matriz_puente = np.sum(tensor_gradiente_pesos_actual * tensor_gradiente_bias_actual, axis = 1) # Tensor con la información para calcular la derivada parcial de J con respecto a la activación de la capa anterior\n",
        "            tensor_puente = np.expand_dims(matriz_puente, axis=2) # Aquí ya pasamos a la siguiente capa, por eso lo que antes era una neurona de la capa anterior, ahora es neurona de la capa actual\n",
        "\n",
        "            matriz_gradiente_bias_actual = np.mean(tensor_gradiente_bias_actual, axis = 0)\n",
        "            matriz_gradiente_pesos_actual = np.mean(tensor_gradiente_pesos_actual, axis = 0)\n",
        "\n",
        "            self.lista_matrices_gradiente_bias.insert(0, matriz_gradiente_bias_actual)\n",
        "            self.lista_matrices_gradiente_pesos.insert(0, matriz_gradiente_pesos_actual)\n",
        "\n",
        "\n",
        "\n",
        "    def norma_cambio(self, alpha): # Devuelve la norma del vector que se obtiene al multiplicar el learning rate por el gradiente de J\n",
        "\n",
        "        cuadrado_gradiente_pesos = sum(np.sum(matriz**2) for matriz in self.lista_matrices_gradiente_pesos) # Suma del cuadrado de las derivadas de todos los pesos\n",
        "        cuadrado_gradiente_bias = sum(np.sum(matriz**2) for matriz in self.lista_matrices_gradiente_bias) # Suma del cuadrado de las derivadas de todos los bias\n",
        "\n",
        "        magnitud_cambio = alpha*(cuadrado_gradiente_pesos + cuadrado_gradiente_bias)**(1/2)\n",
        "\n",
        "        return magnitud_cambio\n",
        "\n",
        "\n",
        "    def producto_punto(self, LMG_pesos_1, LMG_bias_1): # Devuelve el producto punto del gradiente que se le pasa por entrada, con el gradiente de la red (self.lista_matrices_gradiente_pesos y self.lista_matrices_gradiente_bias). LMG son las siglas de lista de matrices gradiente\n",
        "\n",
        "        produto_punto_pesos = sum(np.sum(matriz_1 * matriz_2) for matriz_1, matriz_2 in zip(LMG_pesos_1, self.lista_matrices_gradiente_pesos))\n",
        "        produto_punto_bias = sum(np.sum(matriz_1 * matriz_2) for matriz_1, matriz_2 in zip(LMG_bias_1, self.lista_matrices_gradiente_bias))\n",
        "\n",
        "        return produto_punto_pesos + produto_punto_bias\n",
        "\n",
        "\n",
        "    def imprimir_info_entrenamiento(self, matriz_labels, alpha, contador_visual, magnitud_cambio):\n",
        "\n",
        "        matriz_activacion = self.salida()\n",
        "        costo = self.diccionario_costo[self.string_funcion_costo](matriz_activacion, matriz_labels)\n",
        "\n",
        "        print(f\"Pasos del descenso: {contador_visual}\")\n",
        "        print(f\"magnitud del paso: {magnitud_cambio}\")\n",
        "        print(f\"Costo: {costo}\")\n",
        "        print(f\"alpha: {alpha}\\n\")\n",
        "\n",
        "\n",
        "    def actualizar_parametros(self, alpha): # Actualiza los pesos y los bias de la red, concluyendo así un paso del descenso del gradiente\n",
        "\n",
        "        for i in range(len(self.lista_matrices_gradiente_pesos)):\n",
        "\n",
        "            matriz_gradiente_peso = self.lista_matrices_gradiente_pesos[i]\n",
        "            matriz_gradiente_bias = self.lista_matrices_gradiente_bias[i]\n",
        "\n",
        "            matriz_peso = self.lista_capas[i+1].matriz_pesos\n",
        "            matriz_bias = self.lista_capas[i+1].matriz_bias\n",
        "\n",
        "            matriz_peso_nueva = matriz_peso - alpha * matriz_gradiente_peso\n",
        "            self.lista_capas[i+1].matriz_pesos = matriz_peso_nueva\n",
        "\n",
        "            matriz_bias_nueva = matriz_bias - alpha * matriz_gradiente_bias\n",
        "            self.lista_capas[i+1].matriz_bias = matriz_bias_nueva\n",
        "\n",
        "\n",
        "\n",
        "    def entrenar(self, matriz_entrenamiento, matriz_labels, alpha_inicial, numero_pasos):\n",
        "\n",
        "        alpha = alpha_inicial\n",
        "        cambio_direccion = False\n",
        "        contador = 1\n",
        "        contador_visual = 1\n",
        "\n",
        "        self.actualizar_activaciones(matriz_entrenamiento) # Se crean/actualizan las activaciones de las capas\n",
        "        self.back_propagation(matriz_labels)\n",
        "        self.actualizar_parametros(alpha)\n",
        "\n",
        "        magnitud_cambio = self.norma_cambio(alpha)\n",
        "\n",
        "        self.imprimir_info_entrenamiento(matriz_labels, alpha, contador_visual, magnitud_cambio)\n",
        "\n",
        "        for paso in range(numero_pasos):\n",
        "\n",
        "            self.actualizar_activaciones(matriz_entrenamiento)\n",
        "\n",
        "            lista_matrices_gradiente_pesos = self.lista_matrices_gradiente_pesos.copy() # Paso i del descenso del gradiente\n",
        "            lista_matrices_gradiente_bias = self.lista_matrices_gradiente_bias.copy() # Paso i del descenso del gradiente\n",
        "\n",
        "            self.back_propagation(matriz_labels)\n",
        "            magnitud_cambio = self.norma_cambio(alpha)\n",
        "            self.actualizar_parametros(alpha)\n",
        "\n",
        "            if contador == 100 and cambio_direccion == False:\n",
        "                alpha = 2*alpha\n",
        "                contador = 0\n",
        "\n",
        "            if self.producto_punto(lista_matrices_gradiente_pesos, lista_matrices_gradiente_bias) < 0: # Producto punto entre el gradiente actual y el anterior\n",
        "\n",
        "                cambio_direccion = True\n",
        "                alpha = alpha/2\n",
        "\n",
        "                print(\"El gradiente cambió de dirección!!!\")\n",
        "                self.imprimir_info_entrenamiento(matriz_labels, alpha, contador_visual, magnitud_cambio)\n",
        "\n",
        "\n",
        "            if contador_visual % 10 == 0:\n",
        "                self.imprimir_info_entrenamiento(matriz_labels, alpha, contador_visual, magnitud_cambio)\n",
        "\n",
        "\n",
        "            contador = contador + 1\n",
        "            contador_visual = contador_visual + 1\n",
        "\n",
        "\n",
        "    def entrenar_por_lotes(self, matriz_entrenamiento, matriz_labels, alpha_inicial, numero_pasos, numero_lotes):\n",
        "\n",
        "        total_datos = matriz_entrenamiento.shape[1]\n",
        "        tamaño_lote = total_datos // numero_lotes\n",
        "\n",
        "        for i in range(numero_lotes):\n",
        "            lote_entrenamiento = matriz_entrenamiento[:, i*tamaño_lote : (i+1)*tamaño_lote]\n",
        "            lote_label = matriz_labels[:, i*tamaño_lote : (i+1)*tamaño_lote]\n",
        "            self.entrenar(lote_entrenamiento, lote_label, alpha_inicial, numero_pasos)\n",
        "            print(f\"Lote {i+1} terminado\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probaremos nuestro codigo con el MNIST dataset"
      ],
      "metadata": {
        "id": "jIcotsMyYw7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "MNIST_datset= tf.keras.datasets.mnist.load_data()\n",
        "X_entrenamiento = MNIST_datset[0][0]\n",
        "Y_entrenamiento = MNIST_datset[0][1]\n",
        "X_test = MNIST_datset[1][0]\n",
        "Y_test = MNIST_datset[1][1]\n",
        "\n",
        "X_entrenamiento = X_entrenamiento.astype('float16') / 255\n",
        "X_test = X_test.astype('float16') / 255\n",
        "\n",
        "X_entrenamiento = X_entrenamiento.reshape(-1, 784).T # Aplanamiento\n",
        "X_test = X_test.reshape(-1, 784).T\n",
        "\n",
        "Y_entrenamiento = tf.keras.utils.to_categorical(Y_entrenamiento).T # One-hot encoding\n",
        "Y_test = tf.keras.utils.to_categorical(Y_test).T"
      ],
      "metadata": {
        "id": "K12x3rw0WWvl"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_entrenamiento.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDqCXFG-Xw-J",
        "outputId": "18794061-2aa8-46f9-b690-10c41d2e91b3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 60000)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "red = Red_Neuronal(\"mse\")\n",
        "red.topology([784, 8, 10], [\"identidad\", \"sigmoide\", \"sigmoide\"])\n",
        "\n",
        "print(f\"Acuracy antes del entrenamiento (dataset de prueba): {red.evaluar_MNIST(X_test, Y_test)}\")\n",
        "print(f\"Acuracy antes del entrenamiento (dataset de entrenamiento): {red.evaluar_MNIST(X_entrenamiento, Y_entrenamiento)}\")\n",
        "print(\"\")\n",
        "\n",
        "#red_1.entrenar(X_entrenamiento[:, :10000], Y_entrenamiento[:, :10000], 1, 83)\n",
        "red.entrenar_por_lotes(X_entrenamiento[:, :10000], Y_entrenamiento[:, :10000], 1, 40, 10)\n",
        "\n",
        "print(f\"Acuracy post entrenamiento (dataset de prueba): {red.evaluar_MNIST(X_test, Y_test)}\")\n",
        "print(f\"Acuracy post entrenamiento (dataset de entrenamiento): {red.evaluar_MNIST(X_entrenamiento, Y_entrenamiento)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mMRO9wuR4sm",
        "outputId": "a986f6f3-aaad-4497-85af-c38254c53c39"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acuracy antes del entrenamiento (dataset de prueba): 0.1148\n",
            "Acuracy antes del entrenamiento (dataset de entrenamiento): 0.11663333333333334\n",
            "\n",
            "Pasos del descenso: 1\n",
            "magnitud del paso: 1.1779694608327698\n",
            "Costo: 3.4254879482413396\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 10\n",
            "magnitud del paso: 0.11624048010755404\n",
            "Costo: 0.9742043937406506\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 20\n",
            "magnitud del paso: 0.07170664239957764\n",
            "Costo: 0.9383488660496969\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 30\n",
            "magnitud del paso: 0.05847603098540771\n",
            "Costo: 0.9235727469762065\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 40\n",
            "magnitud del paso: 0.052339946953111637\n",
            "Costo: 0.9140250883712222\n",
            "alpha: 1\n",
            "\n",
            "Lote 1 terminado\n",
            "\n",
            "Pasos del descenso: 1\n",
            "magnitud del paso: 0.052274056713275306\n",
            "Costo: 0.9138759682982829\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 10\n",
            "magnitud del paso: 0.04874093763852009\n",
            "Costo: 0.9091985546388102\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 20\n",
            "magnitud del paso: 0.04588563071529317\n",
            "Costo: 0.9055606074755808\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 30\n",
            "magnitud del paso: 0.04229030358291908\n",
            "Costo: 0.9018436967837586\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 40\n",
            "magnitud del paso: 0.03838787227441709\n",
            "Costo: 0.8979798579534651\n",
            "alpha: 1\n",
            "\n",
            "Lote 2 terminado\n",
            "\n",
            "Pasos del descenso: 1\n",
            "magnitud del paso: 0.03771743909733189\n",
            "Costo: 0.8930469957142239\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 10\n",
            "magnitud del paso: 0.033901419720407375\n",
            "Costo: 0.8895912112562926\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 20\n",
            "magnitud del paso: 0.03024201764800372\n",
            "Costo: 0.8868065894495776\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 30\n",
            "magnitud del paso: 0.026861418893357903\n",
            "Costo: 0.8845734949146724\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 40\n",
            "magnitud del paso: 0.02388450596629279\n",
            "Costo: 0.8828367735923038\n",
            "alpha: 1\n",
            "\n",
            "Lote 3 terminado\n",
            "\n",
            "Pasos del descenso: 1\n",
            "magnitud del paso: 0.024998565170014534\n",
            "Costo: 0.8878950042789961\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 10\n",
            "magnitud del paso: 0.021868475440676504\n",
            "Costo: 0.8857559130302919\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 20\n",
            "magnitud del paso: 0.01946913190672261\n",
            "Costo: 0.8843433070212878\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 30\n",
            "magnitud del paso: 0.017553214666328226\n",
            "Costo: 0.8834092073776266\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 40\n",
            "magnitud del paso: 0.015975398479241915\n",
            "Costo: 0.882804228367208\n",
            "alpha: 1\n",
            "\n",
            "Lote 4 terminado\n",
            "\n",
            "Pasos del descenso: 1\n",
            "magnitud del paso: 0.017851538528838085\n",
            "Costo: 0.8827287056468258\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 10\n",
            "magnitud del paso: 0.01570550155177343\n",
            "Costo: 0.8818187714999658\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 20\n",
            "magnitud del paso: 0.014111833111736586\n",
            "Costo: 0.8813222470999599\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 30\n",
            "magnitud del paso: 0.012875274725466773\n",
            "Costo: 0.8810825880753687\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 40\n",
            "magnitud del paso: 0.011879862284953443\n",
            "Costo: 0.8810095030596249\n",
            "alpha: 1\n",
            "\n",
            "Lote 5 terminado\n",
            "\n",
            "Pasos del descenso: 1\n",
            "magnitud del paso: 0.013416480446923052\n",
            "Costo: 0.8861553620506033\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 10\n",
            "magnitud del paso: 0.011564878225815159\n",
            "Costo: 0.8857060060804927\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 20\n",
            "magnitud del paso: 0.010218684022296818\n",
            "Costo: 0.8855053809743635\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 30\n",
            "magnitud del paso: 0.009203129121677348\n",
            "Costo: 0.8854486565962499\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 40\n",
            "magnitud del paso: 0.00841308745331714\n",
            "Costo: 0.8854777038333973\n",
            "alpha: 1\n",
            "\n",
            "Lote 6 terminado\n",
            "\n",
            "Pasos del descenso: 1\n",
            "magnitud del paso: 0.009394562605790698\n",
            "Costo: 0.8869756202845528\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 10\n",
            "magnitud del paso: 0.00855687624404173\n",
            "Costo: 0.8868892993186728\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 20\n",
            "magnitud del paso: 0.007906658187868183\n",
            "Costo: 0.8868849388704442\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 30\n",
            "magnitud del paso: 0.007385102397226155\n",
            "Costo: 0.8869340852495136\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 40\n",
            "magnitud del paso: 0.00695481479691936\n",
            "Costo: 0.8870190773661089\n",
            "alpha: 1\n",
            "\n",
            "Lote 7 terminado\n",
            "\n",
            "Pasos del descenso: 1\n",
            "magnitud del paso: 0.009454352655081339\n",
            "Costo: 0.8849477019474317\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 10\n",
            "magnitud del paso: 0.008662394517470329\n",
            "Costo: 0.8847669569299706\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 20\n",
            "magnitud del paso: 0.008025537022271316\n",
            "Costo: 0.884698217312656\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 30\n",
            "magnitud del paso: 0.007509118010235684\n",
            "Costo: 0.884708749130582\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 40\n",
            "magnitud del paso: 0.007085714242152033\n",
            "Costo: 0.8847751574838011\n",
            "alpha: 1\n",
            "\n",
            "Lote 8 terminado\n",
            "\n",
            "Pasos del descenso: 1\n",
            "magnitud del paso: 0.0094598643994619\n",
            "Costo: 0.8851118365732972\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 10\n",
            "magnitud del paso: 0.008667634533354996\n",
            "Costo: 0.8848595556470059\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 20\n",
            "magnitud del paso: 0.008056315672405058\n",
            "Costo: 0.8847122770474407\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 30\n",
            "magnitud del paso: 0.0075793558255956624\n",
            "Costo: 0.8846369164314842\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 40\n",
            "magnitud del paso: 0.0072020566799415086\n",
            "Costo: 0.8846111523750967\n",
            "alpha: 1\n",
            "\n",
            "Lote 9 terminado\n",
            "\n",
            "Pasos del descenso: 1\n",
            "magnitud del paso: 0.008719162064578493\n",
            "Costo: 0.8857620782425107\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 10\n",
            "magnitud del paso: 0.008016301807101677\n",
            "Costo: 0.8856435836959488\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 20\n",
            "magnitud del paso: 0.0074934280433422784\n",
            "Costo: 0.8856039690140883\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 30\n",
            "magnitud del paso: 0.00709111320584827\n",
            "Costo: 0.8856150593288382\n",
            "alpha: 1\n",
            "\n",
            "Pasos del descenso: 40\n",
            "magnitud del paso: 0.006771060630626725\n",
            "Costo: 0.8856593496288884\n",
            "alpha: 1\n",
            "\n",
            "Lote 10 terminado\n",
            "\n",
            "Acuracy post entrenamiento (dataset de prueba): 0.2375\n",
            "Acuracy post entrenamiento (dataset de entrenamiento): 0.23635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Justificación de la función de costo logistica\n",
        "\n",
        "Dado un conjunto de datos $\\{(a^{[L-1](k)}, y^{(k)})\\}_{k=1}^m$, donde cada $y^{(k)} \\in \\{0, 1\\}$, y asumiendo que las muestras son independientes, la probabilidad conjunta está dada por:\n",
        "$$\n",
        "P(\\{y^{(k)}\\}_{i=1}^m | W, b) = \\prod_{k=1}^m \\left(a^{[L](k)}\\right)^{y^{(k)}} \\left(1 - a^{[L](k)}\\right)^{1 - y^{(k)}},\n",
        "$$\n",
        "donde $a^{[L](k)}$ es la probabilidad predicha para el ejemplo $k$, calculada como:\n",
        "\n",
        "$$\n",
        "a^{[L](k)} = \\frac{1}{1 + e^{-z^{(k)}}}, \\quad z^{(k)} = W^T a^{[L-1](k)} + b.\n",
        "$$\n",
        "\n",
        "$ $\n",
        "\n",
        "Tomando el logaritmo de la probabilidad conjunta, obtenemos:\n",
        "\n",
        "$$\\ell(W, b) = \\sum_{k=1}^m \\left[ y^{(k)} \\log\\left(a^{[L](k)}\\right) + (1 - y^{(k)}) \\log\\left(1 - a^{[L](k)}\\right) \\right]$$\n",
        "\n",
        "$ $\n",
        "\n",
        "Maximizar $\\ell(W, b)$ es equivalente maximizar $\\frac{1}{m}\\ell(W, b)$, que a su vez es equivalente a minimizar el negativo de esta ultima expresión. Sustituyendo $\\ell(W, b)$ nos queda que\n",
        "\n",
        "$$\n",
        "J(W, b) = -\\frac{1}{m} \\sum_{k=1}^m \\left[ y^{(k)} \\log\\left(a^{[L](k)}\\right) + (1 - y^{(k)}) \\log\\left(1 - a^{[L](k)}\\right) \\right].\n",
        "$$\n",
        "\n",
        "### Interpretación estadística\n",
        "1. El termino ($y^{(k)} \\log\\left(a^{[L](k)}\\right)$): Penaliza predicciones en las que $a^{[L](k)}$ (la probabilidad predicha de $y=1$) sea baja cuando $y^{(k)}=1$. Esto asegura que el modelo asigne alta probabilidad a la clase positiva en los casos donde esta ocurre.\n",
        "\n",
        "2. El termino ($(1 - y^{(k)}) \\log\\left(1 - a^{[L](k)}\\right)$): Penaliza predicciones en las que $a^{[L](k)}$ sea alta cuando $y^{(k)}=0$. Esto asegura que el modelo asigne baja probabilidad a la clase positiva cuando esta no ocurre."
      ],
      "metadata": {
        "id": "k6aK9uQ2-4yv"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}